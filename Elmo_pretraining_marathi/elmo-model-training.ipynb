{"cells":[{"cell_type":"markdown","metadata":{},"source":["## ELMO Implementation"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Marathi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T21:22:57.487344Z","iopub.status.busy":"2024-05-07T21:22:57.486965Z","iopub.status.idle":"2024-05-07T21:23:09.731555Z","shell.execute_reply":"2024-05-07T21:23:09.730537Z","shell.execute_reply.started":"2024-05-07T21:22:57.487318Z"},"trusted":true},"outputs":[],"source":["!pip install indic-nlp-library wandb tqdm\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","import numpy as np\n","from indicnlp.tokenize import indic_tokenize\n","from torch.nn.utils.rnn import pad_sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T21:23:09.733746Z","iopub.status.busy":"2024-05-07T21:23:09.733410Z","iopub.status.idle":"2024-05-07T21:23:39.524936Z","shell.execute_reply":"2024-05-07T21:23:39.523762Z","shell.execute_reply.started":"2024-05-07T21:23:09.733717Z"},"trusted":true},"outputs":[],"source":["import fasttext\n","import fasttext.util\n","ft_model = fasttext.load_model('/kaggle/input/pre-trained-model-indicft/indicnlp.ft.mr.300.bin')\n","word = \"नृत्य\"\n","print(\"Embedding Shape is {}\".format(ft_model.get_word_vector(word)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T21:23:39.527144Z","iopub.status.busy":"2024-05-07T21:23:39.526818Z","iopub.status.idle":"2024-05-07T21:24:11.553945Z","shell.execute_reply":"2024-05-07T21:24:11.552916Z","shell.execute_reply.started":"2024-05-07T21:23:39.527116Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","from indicnlp.tokenize import indic_tokenize\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader\n","import fasttext\n","from tqdm import tqdm\n","\n","folder_path = '/kaggle/input/medium-marathi-dataset'\n","model_path = '/kaggle/input/pre-trained-model-indicft/indicnlp.ft.mr.300.bin' \n","\n","\n","ft_model = fasttext.load_model(model_path)\n","\n","token_to_index = {'<PAD>': 0, '<UNK>': 1, '<SOS>':2, '<EOS>':3}\n","next_token_index = 4  \n","\n","def update_indices(token_list, token_to_index):\n","    global next_token_index\n","    for token in token_list:\n","        if token not in token_to_index:\n","            token_to_index[token] = next_token_index\n","            next_token_index += 1\n","\n","texts = []  \n","threshold = 256\n","\n","for file_name in os.listdir(folder_path):\n","    if file_name.endswith('.txt'):\n","        file_path = os.path.join(folder_path, file_name)\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            text = f.read()\n","        sentences = re.split(r'[।\\n\\.]+', text)\n","        sentences = [\"<SOS> \"+sentence.strip()+\" <EOS>\" for sentence in sentences if sentence.strip()]\n","\n","        for sentence in sentences:\n","            tokens = indic_tokenize.trivial_tokenize(sentence, lang='mr')\n","            update_indices(tokens, token_to_index)\n","            if len(tokens) > threshold:  \n","                continue  \n","            texts.append(sentence)\n","\n","print(f\"Number of sentences processed: {len(texts)}\")\n","\n","class MarathiDataset(Dataset):\n","    def __init__(self, texts, ft_model, token_to_index):\n","        self.texts = texts\n","        self.ft_model = ft_model\n","        self.token_to_index = token_to_index\n","    \n","    def __len__(self):\n","        return len(self.texts)\n","    \n","    def __getitem__(self, idx):\n","        sentence = self.texts[idx]\n","        tokens = indic_tokenize.trivial_tokenize(sentence, lang='mr')\n","        embeddings = [self.ft_model.get_word_vector(token) for token in tokens]  \n","        input_embeddings = torch.tensor(embeddings[:-1], dtype=torch.float)\n","        target_indices = [self.token_to_index.get(token, self.token_to_index['<UNK>']) for token in tokens[1:]]  \n","        target_indices = torch.tensor(target_indices, dtype=torch.long)  \n","        return input_embeddings, target_indices\n","\n","def collate_fn(batch):\n","    (inputs, targets) = zip(*batch)\n","    input_embeddings = pad_sequence(inputs, batch_first=True, padding_value=0.0)\n","    target_sequences = pad_sequence(targets, batch_first=True, padding_value=token_to_index['<PAD>']) \n","    return input_embeddings, target_sequences\n","\n","dataset = MarathiDataset(texts, ft_model, token_to_index)\n","dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n","\n","for input_data, targets in dataloader:\n","    print(f\"Input batch shape: {input_data.shape}\")\n","    print(f\"Target batch shape: {targets.shape}\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T21:28:12.970584Z","iopub.status.busy":"2024-05-07T21:28:12.970185Z","iopub.status.idle":"2024-05-07T21:28:12.983898Z","shell.execute_reply":"2024-05-07T21:28:12.982928Z","shell.execute_reply.started":"2024-05-07T21:28:12.970555Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ELMoLanguageModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n","        super(ELMoLanguageModel, self).__init__()\n","        \n","        self.forward_lstm1 = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n","        self.forward_lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n","        self.backward_lstm1 = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n","        self.backward_lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n","\n","        self.forward_pred = nn.Linear(hidden_dim, vocab_size)\n","        self.backward_pred = nn.Linear(hidden_dim, vocab_size)\n","\n","        self.gamma = nn.Parameter(torch.ones(3)) \n","\n","    def forward(self, x):\n","    \n","        forward_out1, _ = self.forward_lstm1(x)\n","        forward_out2, _ = self.forward_lstm2(forward_out1)\n","\n","        reversed_embeddings = torch.flip(x, [1])\n","        backward_out1, _ = self.backward_lstm1(reversed_embeddings)\n","        backward_out2, _ = self.backward_lstm2(backward_out1)\n","\n","        backward_out1 = torch.flip(backward_out1, [1])\n","        backward_out2 = torch.flip(backward_out2, [1])\n","\n","        forward_predictions = self.forward_pred(forward_out2[:, -1, :])\n","        backward_predictions = self.backward_pred(backward_out2[:, 0, :])\n","\n","        combined_embeddings = self.gamma[0] * x + self.gamma[1] * torch.cat((forward_out1, backward_out1), dim=-1) + self.gamma[2] * torch.cat((forward_out2, backward_out2), dim=-1)\n","\n","        return forward_predictions, backward_predictions, combined_embeddings\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T21:28:13.924685Z","iopub.status.busy":"2024-05-07T21:28:13.924350Z","iopub.status.idle":"2024-05-07T21:28:13.931882Z","shell.execute_reply":"2024-05-07T21:28:13.930926Z","shell.execute_reply.started":"2024-05-07T21:28:13.924661Z"},"trusted":true},"outputs":[],"source":["cuda_available = torch.cuda.is_available()\n","print(\"CUDA Available:\", cuda_available)\n","device = torch.device(\"cuda\" if cuda_available else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T21:28:14.676801Z","iopub.status.busy":"2024-05-07T21:28:14.676458Z","iopub.status.idle":"2024-05-07T21:29:09.510927Z","shell.execute_reply":"2024-05-07T21:29:09.509606Z","shell.execute_reply.started":"2024-05-07T21:28:14.676777Z"},"trusted":true},"outputs":[],"source":["import wandb\n","hidden_dim = 150  \n","num_layers = 2  \n","vocab_size = len(token_to_index) + 1\n","\n","model = ELMoLanguageModel(vocab_size, 300, hidden_dim).to(device)\n","criterion = nn.CrossEntropyLoss(ignore_index=token_to_index['<PAD>']) \n","optimizer = torch.optim.Adam(model.parameters()) \n","\n","# wandb.init(project='Marathi_model_Elmo')\n","\n","\n","num_epochs = 2  \n","for epoch in range(num_epochs):\n","    model.train() \n","    total_loss = 0\n","    for input_data, targets in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n","        input_data, targets = input_data.to(device), targets.to(device)\n","        optimizer.zero_grad()  \n","        forward_pred, backward_pred, _ = model(input_data) \n","                \n","        loss_f = criterion(forward_pred, targets[:, 1]) \n","        loss_b = criterion(backward_pred, targets[:, -1])  \n","\n","        total_loss = loss_f + loss_b\n","        \n","        total_loss.backward()  \n","        optimizer.step()      \n","        total_loss += total_loss.item()\n","    avg_loss = total_loss / len(dataloader)\n","#     wandb.log({\"train_loss\": avg_loss})\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.15f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:36:41.607457Z","iopub.status.idle":"2024-05-05T19:36:41.607832Z","shell.execute_reply":"2024-05-05T19:36:41.607676Z","shell.execute_reply.started":"2024-05-05T19:36:41.607662Z"},"trusted":true},"outputs":[],"source":["model_path = './bilm_marathi_model.pth'\n","torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-05T19:36:41.608985Z","iopub.status.idle":"2024-05-05T19:36:41.609312Z","shell.execute_reply":"2024-05-05T19:36:41.609151Z","shell.execute_reply.started":"2024-05-05T19:36:41.609139Z"},"trusted":true},"outputs":[],"source":["import json\n","\n","mappings_path = './marathi_mappings.json'\n","with open(mappings_path, 'w', encoding='utf-8') as f:\n","    json.dump({\n","        'token_to_index': token_to_index\n","    }, f, ensure_ascii=False, indent=4)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Anology and Similarity (Marathi)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T21:00:07.337962Z","iopub.status.busy":"2024-05-07T21:00:07.337693Z","iopub.status.idle":"2024-05-07T21:00:38.592814Z","shell.execute_reply":"2024-05-07T21:00:38.591831Z","shell.execute_reply.started":"2024-05-07T21:00:07.337940Z"},"trusted":true},"outputs":[],"source":["!pip install indic-nlp-library\n","!pip install pandas pyarrow\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","import re\n","from indicnlp.tokenize import indic_tokenize\n","\n","cuda_available = torch.cuda.is_available()\n","print(\"CUDA Available:\", cuda_available)\n","device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n","\n","class ELMoLanguageModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n","        super(ELMoLanguageModel, self).__init__()\n","        self.forward_lstm1 = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n","        self.forward_lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n","        self.backward_lstm1 = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n","        self.backward_lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n","\n","        self.forward_pred = nn.Linear(hidden_dim, vocab_size)\n","        self.backward_pred = nn.Linear(hidden_dim, vocab_size)\n","        self.gamma = nn.Parameter(torch.ones(3))  \n","        self.freeze_parameters()\n","        \n","    def freeze_parameters(self):\n","        for name, param in self.named_parameters():\n","            if 'gamma' not in name:\n","                param.requires_grad = False\n","\n","    def forward(self, x):\n","        \n","        forward_out1, _ = self.forward_lstm1(x)\n","        forward_out2, _ = self.forward_lstm2(forward_out1)\n","\n","        # Backward LM\n","        reversed_embeddings = torch.flip(x, [1])\n","        backward_out1, _ = self.backward_lstm1(reversed_embeddings)\n","        backward_out2, _ = self.backward_lstm2(backward_out1)\n","\n","        backward_out1 = torch.flip(backward_out1, [1])\n","        backward_out2 = torch.flip(backward_out2, [1])\n","\n","        forward_predictions = self.forward_pred(forward_out2[:, -1, :])\n","        backward_predictions = self.backward_pred(backward_out2[:, 0, :])\n","\n","        combined_embeddings = self.gamma[0] * x + self.gamma[1] * torch.cat((forward_out1, backward_out1), dim=-1) + self.gamma[2] * torch.cat((forward_out2, backward_out2), dim=-1)\n","\n","        return forward_predictions, backward_predictions, combined_embeddings\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T21:02:31.342986Z","iopub.status.busy":"2024-05-07T21:02:31.342077Z","iopub.status.idle":"2024-05-07T21:02:37.935336Z","shell.execute_reply":"2024-05-07T21:02:37.934009Z","shell.execute_reply.started":"2024-05-07T21:02:31.342953Z"},"trusted":true},"outputs":[],"source":["import json\n","import torch\n","import pandas as pd\n","import fasttext\n","import fasttext.util\n","\n","def load_model_and_mappings(model_path, mappings_path):\n","    with open(mappings_path, 'r', encoding='utf-8') as f:\n","        mappings = json.load(f)\n","\n","    token_to_index = mappings['token_to_index']\n","    vocab_size = len(token_to_index) + 1 \n","#     model = BiLM(hidden_dim=128, num_layers=2, vocab_size=vocab_size)\n","    model = ELMoLanguageModel(vocab_size, 300, 150).to(device)\n","    \n","    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","    model.eval()  \n","    \n","    return model, token_to_index\n","\n","\n","model_path = '/kaggle/input/elmo-model-small-dataset/bilm_marathi_model.pth'\n","mappings_path = '/kaggle/input/elmo-model-small-dataset/marathi_mappings.json'\n","\n","model, token_to_index = load_model_and_mappings(model_path, mappings_path)\n","\n","def cosine_similarity(embedding1, embedding2):\n","    return torch.nn.functional.cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0), dim=1).mean()\n","\n","def get_word_embedding(word, ft_model, device, elmo_model):\n","    embeddings = ft_model.get_word_vector(word)\n","    embeddings_tensor = torch.tensor([embeddings], dtype=torch.float).unsqueeze(0).to(device)\n","        _, _, elmo_embeddings = elmo_model(embeddings_tensor)\n","    return elmo_embeddings.squeeze(0)\n","\n","def find_analogy(word_a, word_b, word_c, ft_model, device,elmo_model):\n","    embedding_a = get_word_embedding(word_a, ft_model, device, elmo_model)\n","    embedding_b = get_word_embedding(word_b, ft_model, device, elmo_model)\n","    embedding_c = get_word_embedding(word_c, ft_model, device, elmo_model)\n","\n","    max_similarity = -float('Inf')\n","    word_d = None\n","\n","    analogy_vector = (embedding_b - embedding_a) + embedding_c\n","\n","    for word in ft_model.get_words():\n","        embedding_d = get_word_embedding(word, ft_model, device, elmo_model)\n","        sim = cosine_similarity(analogy_vector.unsqueeze(0), embedding_d.unsqueeze(0))\n","        if sim > max_similarity:\n","            max_similarity = sim\n","            word_d = word\n","\n","    return word_d\n","\n","\n","def evaluate_pairs(pairs, ft_model, device, elmo_model):\n","    for word1, word2 in pairs:\n","        embedding1 = get_word_embedding(word1, ft_model, device, elmo_model)\n","        embedding2 = get_word_embedding(word2, ft_model, device, elmo_model)\n","        sim = cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0))\n","        print(f\"Cosine similarity between {word1} and {word2} is {sim.item()}\")\n","\n","\n","ft_model = fasttext.load_model('/kaggle/input/pre-trained-model-indicft/indicnlp.ft.mr.300.bin')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:02:37.936503Z","iopub.status.idle":"2024-05-07T21:02:37.936848Z","shell.execute_reply":"2024-05-07T21:02:37.936695Z","shell.execute_reply.started":"2024-05-07T21:02:37.936682Z"},"trusted":true},"outputs":[],"source":["vocab_size = len(token_to_index) + 1 \n","elmo_model = ELMoLanguageModel(vocab_size, 300, 150).to(device)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","word_pairs = [('राजा', 'राणी'), ('राजा', 'दलितांना'), ('माणूस', 'खुर्ची'), ('माणूस', 'उडणे')]\n","analogies =  [('राजा', 'माणूस', 'राणी'), ('पॅरिस', 'फ्रान्स', 'रोम')]\n","word_pairs_1 = [('सर्वसाधारण माणूस रस्त्यावर चालत आहे', 'एक माणूस रस्त्यावर चालत आहे'), ('सर्वसाधारण माणूस रस्त्यावर चालत आहे', 'मी खात आहे')]\n","\n","evaluate_pairs(word_pairs, ft_model, device,elmo_model)\n","evaluate_pairs(word_pairs_1, ft_model, device,elmo_model)\n","\n","for a, b, c in analogies:\n","    predicted_d = find_analogy(a, b, c, ft_model, device,elmo_model)\n","    print(f\"{a} is to {b} as {c} is to {predicted_d}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### =============================================================="]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4731583,"sourceId":8028094,"sourceType":"datasetVersion"},{"datasetId":4750435,"sourceId":8054605,"sourceType":"datasetVersion"},{"datasetId":4751467,"sourceId":8056080,"sourceType":"datasetVersion"},{"datasetId":4752195,"sourceId":8057067,"sourceType":"datasetVersion"},{"datasetId":4752208,"sourceId":8057085,"sourceType":"datasetVersion"},{"datasetId":4759164,"sourceId":8066629,"sourceType":"datasetVersion"},{"datasetId":4759390,"sourceId":8066925,"sourceType":"datasetVersion"},{"datasetId":4764681,"sourceId":8074184,"sourceType":"datasetVersion"},{"datasetId":4764872,"sourceId":8074415,"sourceType":"datasetVersion"},{"datasetId":4764989,"sourceId":8074587,"sourceType":"datasetVersion"},{"datasetId":4891241,"sourceId":8244662,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
