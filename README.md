
# NLP Project Dataset

## Data Overview
contents of the dataset are as follows:

### Directory Structure
- **data**
  - This folder contains, Marathi dcorpus for pretraining as well as downstream task data, which are part of IndicGlue datasets
- **Downtasks**
  - This folder contains all the code folders for downtasks
- **Elmo_pretraining_marathi**
  - This folder contains the pretraining code for marathi elmo
  **Pretrained_Marathi_Elmo_model**
  - This folder contains the pretrained marathi model and vocab index file

## NOTE
The input embeddings to the Elmo model is indicnlp.ft.mr.300.bin, which can be downloaded from the internet

## Additional Resources
- **AI4Bharat Dataset:** We used a dataset from AI4Bharat to pretrain the ELMo models for Marathi Language. The dataset can be found here: [AI4Bharat IndicCorp v2](https://github.com/AI4Bharat/IndicBERT/tree/main#indiccorp-v2).

## Conclusion
This repository provides comprehensive resources for training and evaluating the ELMo model Marathi Langauge, contributing significantly to advancements in natural language processing for these languages.
